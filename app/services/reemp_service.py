import json
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from app.core.config import settings


# ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
def get_vectorstore():
    pc = Pinecone(api_key=settings.PINECONE_API_KEY, environment=settings.PINECONE_ENV)
    index = pc.Index(settings.PINECONE_INDEX_NAME_REEMPLOYMENT)
    embeddings = OpenAIEmbeddings(
        openai_api_key=settings.OPENAI_API_KEY, model="text-embedding-ada-002"
    )
    return PineconeVectorStore(index=index, embedding=embeddings, namespace="default")


# LLM ì„¤ì •
def get_llm(model="gpt-4o"):
    return ChatOpenAI(openai_api_key=settings.OPENAI_API_KEY, model=model)


# ì—…ì¢… ë° ì„±ë³„ ì¶”ì¶œ
def extract_field_and_gender(question: str):
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¬ì·¨ì—… ê´€ë ¨ ì—…ì¢…(ì˜ˆ: ì •ë³´í†µì‹ ì—…, ì œì¡°ì—… ë“±)ê³¼ ì„±ë³„(ë‚¨ì„± ë˜ëŠ” ì—¬ì„±)ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. "
                'ì˜ˆì‹œ: {{"field": "ì œì¡°ì—…", "gender": "ì—¬ì„±"}} '
                "ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ê°ê° 'ì¼ë°˜', 'ëª¨ë¦„'ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.",
            ),
            ("human", "{input}"),
        ]
    )
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({"input": question})
    print(f"[ì¶”ì¶œ ê²°ê³¼]: {result}")

    try:
        parsed = json.loads(result)
        field = parsed.get("field", "ì¼ë°˜").strip()
        gender = parsed.get("gender", "ëª¨ë¦„").strip()
        if gender not in ["ë‚¨ì„±", "ì—¬ì„±"]:
            gender = "ëª¨ë¦„"
    except Exception:
        field, gender = "ì¼ë°˜", "ëª¨ë¦„"

    return field, gender


# ì¿¼ë¦¬ ìƒì„±
def reformat_query(field: str, gender: str):
    return f"{field} ì—…ì¢…ì˜ 55ì„¸ ì´ìƒ {gender} ê·¼ë¡œì ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?"


# ê²€ìƒ‰ ë° ìš”ì•½
def search_and_summarize(field: str, gender: str, query: str):
    vectorstore = get_vectorstore()
    llm = get_llm()

    retriever = vectorstore.as_retriever(
        search_kwargs={"k": 10, "filter": {"field": field, "age_group": "55ì„¸ ì´ìƒ"}}
    )

    docs = retriever.invoke(query)
    print(f"ğŸ” Pinecone ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(docs)}")
    for i, doc in enumerate(docs):
        print(f"  [{i+1}] {doc.page_content[:100]}... (metadata: {doc.metadata})")

    if not docs:
        print("fallback: ì „ì²´ì—ì„œ ê²€ìƒ‰ ì‹œë„")
        retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
        docs = retriever.invoke(query)

    if not docs:
        return "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    summary_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ì•„ë˜ contextëŠ” 55ì„¸ ì´ìƒ ê³ ë ¹ìì— ëŒ€í•œ í†µê³„ì…ë‹ˆë‹¤.\n"
                "ë‹¤ìŒ ì¡°ê±´ì— ë§ê²Œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”:\n\n"
                "- íšŒì›ë‹˜ì˜ ì—…ì¢…ì—ëŠ” ê³ ë ¹ì ê·¼ë¡œìê°€ ì „ì²´ ê·¼ë¡œì ì¤‘ ëª‡ ëª…ì¸ì§€ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.\n"
                "- ìš”ì²­ ì„±ë³„ì´ 'ë‚¨ì„±' ë˜ëŠ” 'ì—¬ì„±'ì¼ ê²½ìš°, í•´ë‹¹ ì„±ë³„ ê³ ë ¹ì ìˆ˜ì™€ ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨(%)ì„ ê³„ì‚°í•´ì„œ í¬í•¨í•´ ì£¼ì„¸ìš”.\n"
                "- ì—…ì¢…ì˜ ë¹„ì „ê³¼ ì¬ì·¨ì—… ê°€ëŠ¥ì„±ì€ GPTê°€ ììœ ë¡­ê²Œ ì˜ˆì¸¡í•´ ì£¼ì„¸ìš”.\n\n"
                "**í˜•ì‹ ì˜ˆì‹œ**:\n"
                "íšŒì›ë‹˜ì´ ì¢…ì‚¬í•˜ëŠ” ì œì¡°ì—… ë¶„ì•¼ì—ëŠ” ê³ ë ¹ì ê·¼ë¡œì 11ë§Œ ëª…(ì „ì²´ 118ë§Œ ëª… ì¤‘)ì´ ê·¼ë¬´ ì¤‘ì´ë©°, ì—¬ì„±ì€ ì•½ 1.0%ì¸ 11,679ëª…ì´ ì¢…ì‚¬ ì¤‘ì…ë‹ˆë‹¤. í•´ë‹¹ ì—…ì¢…ì€ ì•ˆì •ì ì¸ ê¸°ìˆ  ê¸°ë°˜ìœ¼ë¡œ ì¬ì·¨ì—… ê¸°íšŒê°€ ë³´í†µ ìˆ˜ì¤€ì´ë©°, ìë™í™”ë¡œ ì¸í•œ ë³€í™”ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
            ),
            ("human", "{input}"),
            ("system", "ì°¸ê³  ë¬¸ì„œ:\n{context}"),
        ]
    )

    document_chain = create_stuff_documents_chain(
        llm=llm, prompt=summary_prompt, output_parser=StrOutputParser()
    )

    rag_chain = create_retrieval_chain(retriever, document_chain)
    result = rag_chain.invoke({"input": query})

    return result.get("answer") if isinstance(result, dict) else str(result)


# ìµœì¢… API
def get_final_reemployment_analysis(user_question: str):
    field, gender = extract_field_and_gender(user_question)
    query = reformat_query(field, gender)
    answer = search_and_summarize(field, gender, query)
    return {"answer": answer}
