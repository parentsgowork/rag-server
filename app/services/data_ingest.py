import os
import pandas as pd
from dotenv import load_dotenv
import openai
from pinecone import Pinecone, ServerlessSpec
from app.core.config import settings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
openai.api_key = settings.OPENAI_API_KEY
index_name = settings.PINECONE_INDEX_NAME_REEMPLOYMENT
file_path = settings.DATA_PATH_REEMPLOYMENT_ANALYSIS

# Pinecone ì´ˆê¸°í™”
pc = Pinecone(api_key=settings.PINECONE_API_KEY)

# ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
if index_name in pc.list_indexes().names():
    pc.delete_index(index_name)

pc.create_index(
    name=index_name,
    dimension=1536,
    metric='cosine',
    spec=ServerlessSpec(
        cloud='aws',
        region='us-east-1'
    )
)

print("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ:", pc.list_indexes().names())

# ì¸ë±ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
index = pc.Index(index_name)

# CSV ë¡œë“œ í•¨ìˆ˜ (ë‘ ë²ˆì§¸ ì¤„ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì‚¬ìš©)
def load_clean_dataframe(file_path):
    df = pd.read_csv(file_path, encoding="cp949", header=1)
    return df

# í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
def text_to_vector(text):
    if not text.strip():
        print("ë¹ˆ ë¬¸ìì—´ ë°œê²¬:", text)
        return None
    try:
        resp = openai.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return resp.data[0].embedding
    except Exception as e:
        print(f"âŒ OpenAI ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return None

# ë°ì´í„° ì—…ë¡œë“œ í•¨ìˆ˜
def ingest_data(file_path):
    df = load_clean_dataframe(file_path)
    print("í…Œì´ë¸” ì—´ ì´ë¦„:", df.columns.tolist())
    print("(í…ŒìŠ¤íŠ¸) í…Œì´ë¸” ì²˜ìŒ 3í–‰:\n", df.head(3))

    vectors = []
    for i, row in df.iterrows():
        # ìì—°ì–´ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ ìƒì„±
        text = (
            f"{row['êµ¬ë¶„ë³„(2)']} ì—…ì¢…ì˜ ì‚¬ì—…ì¥ ìˆ˜ëŠ” {row['ì‚¬ì—…ì¥ (ê°œ)']}ê°œì´ê³ , "
            f"ì „ì²´ ê·¼ë¡œì ìˆ˜ëŠ” {row['ì „ì²´ ê·¼ë¡œì (ëª…)']}ëª…ì…ë‹ˆë‹¤. "
            f"55ì„¸ ì´ìƒ ê·¼ë¡œìëŠ” {row['55ì„¸ ì´ìƒ ê·¼ë¡œì (ëª…)']}ëª…ì´ë©°, "
            f"ì´ ì¤‘ ë‚¨ì„±ì€ {row['55ì„¸ ì´ìƒ ë‚¨ì„±ê·¼ë¡œì (ëª…)']}ëª…, ì—¬ì„±ì€ {row['55ì„¸ ì´ìƒ ì—¬ì„±ê·¼ë¡œì (ëª…)']}ëª…ì…ë‹ˆë‹¤."
        )

        vector = text_to_vector(text)
        if vector is None:
            continue

        metadata = {
            "field": str(row['êµ¬ë¶„ë³„(2)']),
            "age_group": "55ì„¸ ì´ìƒ",
            "text": text
        }

        vectors.append((str(i), vector, metadata))

    print(f"ìƒì„±ëœ ë²¡í„° ê°œìˆ˜: {len(vectors)}")

    if not vectors:
        print("ì—…ë¡œë“œí•  ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    batch_size = 100
    for i in range(0, len(vectors), batch_size):
        chunk = vectors[i: i + batch_size]
        print(f"â¬†ï¸ ì—…ë¡œë“œ ì¤‘... {i} ~ {i + len(chunk)}ê°œ")
        index.upsert(vectors=chunk, namespace="default")

    print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
    stats = index.describe_index_stats()
    print("ğŸ“Š ì¸ë±ìŠ¤ í†µê³„:", stats)

if __name__ == "__main__":
    ingest_data(file_path)
