import os
import pandas as pd
from dotenv import load_dotenv
import openai
from pinecone import Pinecone, ServerlessSpec
from app.core.config import settings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
openai.api_key = settings.OPENAI_API_KEY
index_name = settings.PINECONE_INDEX_NAME_REEMPLOYMENT
file_path = settings.DATA_PATH_REEMPLOYMENT_ANALYSIS

# Pinecone ì´ˆê¸°í™” (ìµœì‹  ë°©ì‹)
pc = Pinecone(api_key=settings.PINECONE_API_KEY)

# ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
if index_name in pc.list_indexes().names():
    pc.delete_index(index_name)

pc.create_index(
    name=index_name,
    dimension=1536,
    metric='cosine',
    spec=ServerlessSpec(
        cloud='aws',
        region='us-east-1'
    )
)

print("\u2705 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ:", pc.list_indexes().names())

# ì¸ë±ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
index = pc.Index(index_name)

# CSV ë¡œë“œ í•¨ìˆ˜ (2í–‰ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì‚¬ìš©)
def load_clean_dataframe(file_path):
    df_raw = pd.read_csv(file_path, encoding="cp949", header=None)
    df = df_raw[2:].reset_index(drop=True)
    df.columns = df_raw.iloc[1].values
    return df

# í…ìŠ¤íŠ¸ â†’ ë²¡í„°

def text_to_vector(text):
    if not text.strip():
        print("ë¹ˆ ë¬¸ìì—´ ë°œê²¬:", text)
        return None
    try:
        response = openai.embeddings.create(
            input=text,
            model="text-embedding-ada-002"
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"âŒ OpenAI ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return None

# ì—…ë¡œë“œ í•¨ìˆ˜
def ingest_data(file_path):
    df = load_clean_dataframe(file_path)
    print("í…Œì´ë¸” ì—´ ì´ë¦„:", df.columns.tolist())
    print("í…Œì´ë¸” ì²˜ìŒ 3í–‰:\n", df.head(3))

    vectors = []
    for i, row in df.iterrows():
        text = " ".join([f"{col}: {val}" for col, val in zip(df.columns, row) if pd.notnull(val)])
        vector = text_to_vector(text)

        if vector is None:
            print(f"âŒ ë²¡í„° ìƒì„± ì‹¤íŒ¨: row {i}")
            continue

        metadata = {str(col): str(val) for col, val in zip(df.columns, row)}
        vectors.append((str(i), vector, metadata))

    print(f"âœ… ìƒì„±ëœ ë²¡í„° ê°œìˆ˜: {len(vectors)}")

    if not vectors:
        print("âŒ ì—…ë¡œë“œí•  ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    batch_size = 100
    for i in range(0, len(vectors), batch_size):
        print(f"ì—…ë¡œë“œ ì¤‘... {i} ~ {i + batch_size}ê°œ")
        index.upsert(vectors=vectors[i:i + batch_size], namespace="default")

    print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
    stats = index.describe_index_stats()
    print("ğŸ“Š ì¸ë±ìŠ¤ í†µê³„:", stats)

# ì‹¤í–‰
if __name__ == "__main__":
    ingest_data(file_path)
