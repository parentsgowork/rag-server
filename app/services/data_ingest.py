import os
import pandas as pd
from dotenv import load_dotenv
import openai
from pinecone import Pinecone, ServerlessSpec
from app.core.config import settings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
openai.api_key = settings.OPENAI_API_KEY
index_name = settings.PINECONE_INDEX_NAME_REEMPLOYMENT
file_path = settings.DATA_PATH_REEMPLOYMENT_ANALYSIS

# Pinecone ì´ˆê¸°í™” (ìµœì‹  ë°©ì‹)
pc = Pinecone(api_key=settings.PINECONE_API_KEY)

# ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±
if index_name in pc.list_indexes().names():
    pc.delete_index(index_name)

pc.create_index(
    name=index_name,
    dimension=1536,
    metric='cosine',
    spec=ServerlessSpec(
        cloud='aws',
        region='us-east-1'
    )
)

print("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ:", pc.list_indexes().names())

# ì¸ë±ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
index = pc.Index(index_name)

# CSV ë¡œë“œ í•¨ìˆ˜ (2í–‰ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì‚¬ìš©)
def load_clean_dataframe(file_path):
    df_raw = pd.read_csv(file_path, encoding="cp949", header=None)
    df = df_raw[2:].reset_index(drop=True)
    df.columns = df_raw.iloc[1].values
    return df

# í…ìŠ¤íŠ¸ â†’ ë²¡í„°
def text_to_vector(text):
    if not text.strip():
        print("ë¹ˆ ë¬¸ìì—´ ë°œê²¬:", text)
        return None
    try:
        # ìµœì‹  OpenAI SDK ë°©ì‹
        resp = openai.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return resp.data[0].embedding  
    except Exception as e:
        print(f"âŒ OpenAI ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return None


# ì—…ë¡œë“œ í•¨ìˆ˜
def ingest_data(file_path):
    df = load_clean_dataframe(file_path)
    print("í…Œì´ë¸” ì—´ ì´ë¦„:", df.columns.tolist())
    print("í…Œì´ë¸” ì²˜ìŒ 3í–‰:\n", df.head(3))

    vectors = []
    for i, row in df.iterrows():
        text = " ".join(
            f"{col}: {val}"
            for col, val in zip(df.columns, row)
            if pd.notnull(val)
        )
        vector = text_to_vector(text)
        if vector is None:
            continue

        metadata = {
            str(col): str(val)
            for col, val in zip(df.columns, row)
            if pd.notnull(val)
        }
        metadata["text"] = text
        metadata["age_group"] = "55ì„¸ ì´ìƒ"
        metadata["field"] = metadata.get("êµ¬ë¶„ë³„(2)", "")

        vectors.append((str(i), vector, metadata))

    print(f"âœ… ìƒì„±ëœ ë²¡í„° ê°œìˆ˜: {len(vectors)}")
    if not vectors:
        print("âŒ ì—…ë¡œë“œí•  ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    batch_size = 100
    for i in range(0, len(vectors), batch_size):
        chunk = vectors[i : i + batch_size]
        print(f"ì—…ë¡œë“œ ì¤‘... {i} ~ {i + len(chunk)}ê°œ")
        index.upsert(vectors=chunk, namespace="default")

    print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")
    stats = index.describe_index_stats()
    print("ğŸ“Š ì¸ë±ìŠ¤ í†µê³„:", stats)

if __name__ == "__main__":
    ingest_data(file_path)
