from datetime import datetime
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone
from app.core.config import settings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# ì˜¤ëŠ˜ ë‚ ì§œ
current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"í˜„ì¬ ë‚ ì§œ ë° ì‹œê°„: {current_date}")

# ë²¡í„°ìŠ¤í† ì–´ ì¤€ë¹„
def get_vectorstore():
    pc = Pinecone(api_key=settings.PINECONE_API_KEY, environment=settings.PINECONE_ENV)
    index = pc.Index(settings.PINECONE_INDEX_NAME_REEMPLOYMENT)
    embeddings = OpenAIEmbeddings(openai_api_key=settings.OPENAI_API_KEY)
    return PineconeVectorStore(index=index, embedding=embeddings, text_key="text")

# LLM ì¤€ë¹„
def get_llm(model="gpt-4o"):
    return ChatOpenAI(openai_api_key=settings.OPENAI_API_KEY, model=model)

# 1ë‹¨ê³„: ì—…ì¢… + ì„±ë³„ ì¶”ì¶œ
def extract_field_and_gender(question: str):
    llm = get_llm()

    extraction_prompt = ChatPromptTemplate.from_messages([
        ("system", 
        "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¬ì·¨ì—… ê´€ë ¨ ì—…ì¢…(ì˜ˆ: ì •ë³´í†µì‹ ì—…, ë¶€ë™ì‚°ì—…, ì œì¡°ì—… ë“±)ê³¼ ì„±ë³„(ë‚¨ì„± ë˜ëŠ” ì—¬ì„±)ì„ JSON í˜•íƒœë¡œ ì¶”ì¶œí•˜ì„¸ìš”. "
        "ì˜ˆì‹œ: {{\"field\": \"ë¶€ë™ì‚°ì—…\", \"gender\": \"ì—¬ì„±\"}}. "
        "ì—…ì¢…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ 'ì¼ë°˜', ì„±ë³„ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ 'ëª¨ë¦„'ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”."
        ),
        ("human", "{input}")
    ])

    chain = extraction_prompt | llm | StrOutputParser()
    extraction_result = chain.invoke({"input": question})
    print(f"ğŸ¯ ì¶”ì¶œ ê²°ê³¼: {extraction_result}")

    try:
        result_dict = eval(extraction_result)
        field = result_dict.get("field", "ì¼ë°˜")
        gender = result_dict.get("gender", "ëª¨ë¦„")
    except:
        field = "ì¼ë°˜"
        gender = "ëª¨ë¦„"

    return field.strip(), gender.strip()

# 2ë‹¨ê³„: ì¿¼ë¦¬ ìµœì í™”
def reformat_query(field: str, gender: str):
    return f"{field} ì—…ì¢…ì˜ 55ì„¸ ì´ìƒ {gender} ê·¼ë¡œì ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?"

# 3ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ + ìš”ì•½
def search_and_summarize(field: str, gender: str, optimized_query: str):
    llm = get_llm()
    vectorstore = get_vectorstore()

    # ğŸ”¥ ë²¡í„° + í•„í„° ë™ì‹œ ê²€ìƒ‰
    retriever = vectorstore.as_retriever(search_kwargs={
        "k": 10,
        "filter": {
            "field": {"$contains": field},  # í•„í„°ëŠ” ì—¬ì „íˆ ê±¸ì–´ì£¼ë˜
            "age_group": "55ì„¸ ì´ìƒ"
        }
    })

    # ì¿¼ë¦¬ ìì²´ë¥¼ ì„ë² ë”© â†’ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = retriever.invoke(optimized_query)  # â† ì—¬ê¸°ë§Œ ìˆ˜ì •
    print(f"ğŸ” Pinecone ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(docs)}")
    
    for idx, doc in enumerate(docs):
        print(f"  [{idx+1}] {doc.page_content[:100]}... (metadata: {doc.metadata})")

    if not docs:
        print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. fallbackìœ¼ë¡œ ì „ì²´ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        fallback_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
        docs = fallback_retriever.get_relevant_documents(optimized_query)

    if not docs:
        return "ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # ìš”ì•½ ì§€ì‹œ
    system_prompt = (
        f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {current_date}ì…ë‹ˆë‹¤.\n"
        f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì„±ë³„ì€ {gender}ì…ë‹ˆë‹¤.\n\n"
        "context(ë¬¸ì„œ)ë¡œë¶€í„° ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:\n"
        "- ì—…ì¢…ëª…\n"
        "- 55ì„¸ ì´ìƒ ì „ì²´ ê·¼ë¡œì ìˆ˜\n"
        "- 55ì„¸ ì´ìƒ ë‚¨ì„±/ì—¬ì„± ê·¼ë¡œì ìˆ˜\n"
        "- ì „ì²´ ê·¼ë¡œì ëŒ€ë¹„ í•´ë‹¹ ì„±ë³„ ë¹„ìœ¨(%)\n"
        "- ì—…ì¢…ì˜ ë¹„ì „\n"
        "- ì¬ì·¨ì—… ê°€ëŠ¥ì„±\n"
        "- ì¡°ì–¸ í•œ ë§ˆë””\n\n"
        "**ë‹µë³€ì€ ë°˜ë“œì‹œ 3ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.**\n"
        "ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 'ì•Œ ìˆ˜ ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”."
    )

    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
        ("system", "ì°¸ê³  ë¬¸ì„œ:\n{context}")
    ])

    document_chain = create_stuff_documents_chain(
        llm=llm,
        prompt=qa_prompt,
        output_parser=StrOutputParser()
    )

    retriever_chain = create_retrieval_chain(lambda _: docs, document_chain)

    result = retriever_chain.invoke({"input": optimized_query})

    return result.get("answer") if isinstance(result, dict) else str(result)

# ìµœì¢… API
def get_final_reemployment_analysis(user_question: str):
    field, gender = extract_field_and_gender(user_question)
    optimized_query = reformat_query(field, gender)
    summary = search_and_summarize(field, gender, optimized_query)

    return {
        "answer": summary
    }
